{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2018.4.25 Bookclub QuickNote\n",
    "    \n",
    "    p: distribution we want to know (model)\n",
    "    q: distribution we use to approximate (guide)\n",
    "    \n",
    "    guide: Since we don't know how to describe model, we would get sample from guide (known distribution)\n",
    "\n",
    "    ELBO: over q distribustion\n",
    "    ELBO is lowerbound for p\n",
    "    If you want to maximize log p , equals to maxmize ELBO\n",
    "    \n",
    "    KL divergence: Similarity between q and p\n",
    "    In case that we want to get p, we intruduce a q (depending on our experince) \n",
    "        --> q and p get closer by KL divergence --> we can get good θ\n",
    "\n",
    "    SVI: \n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "    Solve θ automatically\n",
    "    \n",
    "    A simple example:\n",
    "    Slight bias coin, would like to come out how it tends to be positve (want to find q)\n",
    "    Bernoulli distribution identity: p^x * (1-p) ^ 1-x \n",
    "     \n",
    "    Prior: Use a assumed distrubution to guess p\n",
    "    Posterior: Get experience from this time, and become next time's prior\n",
    "    We can get a pre-assumption for p (value in 0~1), and that is close to 0.5\n",
    "    --> Use beta distribution(10. 10)\n",
    "    However, if we use Maximum likelihood, p is 0.6. (6 positive and 4 negative)\n",
    "    \n",
    "    Like GAN, Maximum likelihood and BETA distribution fight \n",
    "       \n",
    "    程式：\n",
    "    model: \n",
    "    guide: Beta(15, 15)\n",
    "    \n",
    "    (比較底層的內容，可能code沒有寫出來)\n",
    "    取sample:\n",
    "    如果要對一個f(x)取積分，但不知道長相\n",
    "    那就是要做sample，去近似每段範圍的面積\n",
    "    等距取樣可能會是不好的估計，該怎麼有效取樣呢？\n",
    "    \n",
    "    或是找一個function去蓋住f(x), 從function去sample, 用此function去推f(x)的長相\n",
    "    \n",
    "    在CV裡面，有甚麼example in reality?\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "    Need \n",
    "        1. real data\n",
    "        2. model: for guess distribution\n",
    "        3. guide: introduce a parameterized distribution (感覺上是輔佐猜測model的distribution)\n",
    "        4. optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variational inference (機率圖模型)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "    observations ⟺ pyro.observe\n",
    "    latent random variables ⟺ pyro.sample\n",
    "    parameters ⟺ pyro.param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guide (variational distribution)\n",
    "    Introduce a parameterized distribution\n",
    "    1. model() and guide() needs to have a matching sample statement \n",
    "    2. Learning will be setup as an optimization problem where each iteration of training takes a step in  space that moves the guide closer to the exact posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELBO (evidence lower bound)\n",
    "     At high level variational inference is easy: all we need to do is define a guide and compute gradients of the ELBO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVI Class\n",
    "    In Pyro the machinery for doing variational inference is encapsulated in the SVI class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.infer import SVI\n",
    "# svi = SVI(model, guide, optimizer, loss=\"ELBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    "    Pyro needs to dynamically generate an optimizer for each parameter the first time it appears during learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.optim import Adam\n",
    "\n",
    "adam_params = {\"lr\": 0.005, \"betas\": (0.95, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "def per_param_callable(module_name, param_name, tags):\n",
    "    if 'param_name' == 'my_special_parameter':\n",
    "        return {\"lr\": 0.010}\n",
    "    else:\n",
    "        return {\"lr\": 0.001}\n",
    "\n",
    "optimizer = Adam(per_param_callable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple example\n",
    "#### We finish with a simple example. You’ve been given a two-sided coin. You want to determine whether the coin is fair or not, i.e. whether it falls heads or tails with the same frequency. You have a prior belief about the likely fairness of the coin based on two observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions as dist\n",
    "\n",
    "def model(data):\n",
    "    # define the hyperparameters that control the beta prior\n",
    "    alpha0 = Variable(torch.Tensor([10.0]))\n",
    "    beta0 = Variable(torch.Tensor([10.0]))\n",
    "    # sample f from the beta prior\n",
    "    f = pyro.sample(\"latent_fairness\", dist.beta, alpha0, beta0)\n",
    "    # loop over the observed data\n",
    "    for i in range(len(data)):\n",
    "        # observe datapoint i using the bernoulli\n",
    "        # likelihood Bernoulli(f)\n",
    "        pyro.observe(\"obs_{}\".format(i), dist.bernoulli,\n",
    "                     data[i], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Our next task is to define a corresponding guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(data):\n",
    "    # define the initial values of the two variational parameters\n",
    "    log_alpha_q_0 = Variable(torch.Tensor([np.log(15.0)]),\n",
    "                             requires_grad=True)\n",
    "    log_beta_q_0 = Variable(torch.Tensor([np.log(15.0)]),\n",
    "                            requires_grad=True)\n",
    "    # register the two variational parameters with Pyro\n",
    "    log_alpha_q = pyro.param(\"log_alpha_q\", log_alpha_q_0)\n",
    "    log_beta_q = pyro.param(\"log_beta_q\", log_beta_q_0)\n",
    "    alpha_q, beta_q = torch.exp(log_alpha_q), torch.exp(log_beta_q)\n",
    "    # sample latent_fairness from the distribution\n",
    "    # Beta(alpha_q, beta_q)\n",
    "    pyro.sample(\"latent_fairness\", dist.beta, alpha_q, beta_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(model, guide, optimizer, loss=\"ELBO\")\n",
    "\n",
    "n_steps = 5000\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    svi.step(data)\n",
    "    \n",
    "### Note that in the step() method we pass in the data, which then get passed to the model and guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The only thing we’re missing at this point is some data. So let’s create some data and assemble all the code snippets above into a complete script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................\n",
      "based on the data and our prior belief, the fairness of the coin is 0.540 +- 0.090\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pyro\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI\n",
    "import pyro.distributions as dist\n",
    "\n",
    "# clear the param store in case we're in a REPL\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# create some data with 6 observed heads and 4 observed tails\n",
    "data = []\n",
    "for _ in range(6):\n",
    "    data.append(Variable(torch.ones(1)))\n",
    "for _ in range(4):\n",
    "    data.append(Variable(torch.zeros(1)))\n",
    "\n",
    "def model(data):\n",
    "    # define the hyperparameters that control the beta prior\n",
    "    alpha0 = Variable(torch.Tensor([10.0]))\n",
    "    beta0 = Variable(torch.Tensor([10.0]))\n",
    "    # sample f from the beta prior\n",
    "    f = pyro.sample(\"latent_fairness\", dist.beta, alpha0, beta0)\n",
    "    # loop over the observed data\n",
    "    for i in range(len(data)):\n",
    "        # observe datapoint i using the bernoulli likelihood\n",
    "        pyro.observe(\"obs_{}\".format(i), dist.bernoulli, data[i], f)\n",
    "\n",
    "def guide(data):\n",
    "    # define the initial values of the two variational parameters\n",
    "    # we initialize the guide near the model prior (except a bit sharper)\n",
    "    log_alpha_q_0 = Variable(torch.Tensor([np.log(15.0)]), requires_grad=True)\n",
    "    log_beta_q_0 = Variable(torch.Tensor([np.log(15.0)]), requires_grad=True)\n",
    "    # register the two variational parameters with Pyro\n",
    "    log_alpha_q = pyro.param(\"log_alpha_q\", log_alpha_q_0)\n",
    "    log_beta_q = pyro.param(\"log_beta_q\", log_beta_q_0)\n",
    "    alpha_q, beta_q = torch.exp(log_alpha_q), torch.exp(log_beta_q)\n",
    "    # sample latent_fairness from Beta(alpha_q, beta_q)\n",
    "    pyro.sample(\"latent_fairness\", dist.beta, alpha_q, beta_q)\n",
    "\n",
    "# setup the optimizer\n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(model, guide, optimizer, loss=\"ELBO\", num_particles=7)\n",
    "\n",
    "n_steps = 4000\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    svi.step(data)\n",
    "    if step % 100 == 0:\n",
    "        print('.', end='')\n",
    "\n",
    "# grab the learned variational parameters\n",
    "alpha_q = torch.exp(pyro.param(\"log_alpha_q\")).data.numpy()[0]\n",
    "beta_q = torch.exp(pyro.param(\"log_beta_q\")).data.numpy()[0]\n",
    "\n",
    "# here we use some facts about the beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "\n",
    "# 2018.4.25 add comment\n",
    "# beta distribution mean\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * np.sqrt(factor)\n",
    "\n",
    "print(\"\\nbased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
